{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Open Power System Data: Renewable power plants\n",
    "\n",
    "\n",
    "## Part 1: Download and processing of the original data\n",
    "\n",
    "This script downlads and extracts the original data of renewable power plant lists from the data sources, processes and merges them. It subsequently adds the geolocation for each power plant and gives an overview over the structure of the data frame. Finally it saves the data frame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents \n",
    "\n",
    "* [1. Script setup](#1.-Script-setup)\n",
    "* [2. Settings](#2.-Settings)\n",
    "    * [2.1 Choose download option](#2.1-Choose-download-option)\n",
    "    * [2.2 Download function](#2.2-Download-function)\n",
    "    * [2.3 Setup translation dictionaries](#2.3-Setup-translation-dictionaries)\n",
    "* [3. Download and process per country](#3.-Download-and-process-per-country)\n",
    "    * [3.1 Germany DE](#3.1-Germany-DE)\n",
    "        * [3.1.1 Download and read](#3.1.1-Download-and-read)\n",
    "        * [3.1.2 Translate column names](#3.1.2-Translate-column-names)\n",
    "        * [3.1.3 Add data source and missing information](#3.1.3-Add-data-source-and-missing-information)\n",
    "        * [3.1.4 Merge DataFrames and choose columns](#3.1.4-Merge-DataFrames-and-choose-columns)\n",
    "        * [3.1.5 Translate values and harmonize energy source](#3.1.5-Translate-values-and-harmonize-energy-source)\n",
    "        * [3.1.6 Georeferencing](#3.1.6-Georeferencing)\n",
    "        * [3.1.7 Save](#3.1.7-Save)\n",
    "    * [3.2 Denmark DK](#3.2-Denmark-DK)\n",
    "        * [3.2.1 Download and read](#3.2.1-Download-and-read)\n",
    "        * [3.2.2 Translate column names](#3.2.2-Translate-column-names)\n",
    "        * [3.2.3 Add data source and missing information](#3.2.3-Add-data-source-and-missing-information)\n",
    "        * [3.2.4 Translate values and harmonize energy source](#3.2.4-Translate-values-and-harmonize-energy-source)\n",
    "        * [3.2.5 Georeferencing](#3.1.5-Georeferencing)\n",
    "        * [3.2.6 Merge DataFrames and choose columns](#3.2.6-Merge-DataFrames-and-choose-columns)        \n",
    "        * [3.2.7 Save](#3.1.7-Save)\n",
    "    * [3.3 France FR](#3.3-France-FR)\n",
    "        * [3.3.1 Download and read](#3.3.1-Download-and-read)\n",
    "        * [3.3.2 Rearrange columns and translate column names](#3.3.2-Rearragne-columns-and-translate-column-names)\n",
    "        * [3.3.3 Add data source](#3.3.3-Add-data-source)\n",
    "        * [3.3.4 Translate values and harmonize energy source](#3.3.4-Translate-values-and-harmonize-energy-source)\n",
    "        * [3.3.5 Transform MW to kW](#3.3.5-Transform-MW-to-kW)\n",
    "        * [3.3.6 Georeferencing](#3.3.6-Georeferencing)\n",
    "        * [3.3.7 Save](#3.3.7-Save)\n",
    "    * [3.4 Poland PL](#3.4-Poland-PL)\n",
    "        * [3.4.1 Download and read](#3.4.1-Download-and-read)\n",
    "        * [3.4.2 Rearrange data from rtf-file](#3.4.2-Rearrange-data-from-rtf-file)\n",
    "        * [3.4.3 Add data source](#3.4.3-Add-data-source)\n",
    "        * [3.4.4 Translate values and harmonize energy source](#3.4.4-Translate-values-and-harmonize-energy-source)\n",
    "        * [3.4.5 Transform MW to kW](#3.4.5-Transform-MW-to-kW)\n",
    "        * [3.4.6 Georeferencing (missing)](#3.4.6-Georeferencing-(missing)\n",
    "        * [3.4.7 Save](#3.4.7-Save)\n",
    "* [Part 2: Validation and output](validation_and_output.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Script setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing all necessary Python libraries for this Script\n",
    "\n",
    "from collections import OrderedDict\n",
    "import io\n",
    "import json\n",
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "import posixpath\n",
    "import urllib.parse\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests \n",
    "import sqlite3 \n",
    "import logging\n",
    "import getpass\n",
    "import utm # for transforming geoinformation in the utm-format\n",
    "import re # provides regular expression matching operations\n",
    "\n",
    "# Starting from ipython 4.3.0 logging is not directing its ouput to the out cell. It might be operating system related but \n",
    "# until the issue is fixed, we are going to use print(). \n",
    "# Issue on Github: https://github.com/ipython/ipykernel/issues/111\n",
    "\n",
    "# Set up a log \n",
    "logger = logging.getLogger('notebook')\n",
    "logger.setLevel('INFO')\n",
    "nb_root_logger = logging.getLogger()\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s'\\\n",
    "                              '- %(message)s',datefmt='%d %b %Y %H:%M:%S')\n",
    "\n",
    "# Create input and output folders if they don't exist\n",
    "os.makedirs('input/original_data', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)\n",
    "os.makedirs('output/renewable_power_plants', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Choose download option\n",
    "The original data can either be downloaded from the original data sources as specified below or from the opsd-Server. Default option is to download from the original sources as the aim of the project is to stay as close to original sources as possible. However, if problems with downloads e.g. due to changing urls occur, you can still run the script with the original data from the opsd_server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "download_from = 'original_sources'\n",
    "# download_from = 'opsd_server' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if download_from == 'opsd_server':\n",
    "\n",
    "# While OPSD is in beta, we need to supply authentication\n",
    "    password = getpass.getpass('Please enter the beta user password:')\n",
    "    session = requests.session()\n",
    "    session.auth = ('beta', password) \n",
    "\n",
    "# Specify direction to original_data folder on the opsd data server\n",
    "    url_opsd = 'http://data.open-power-system-data.org/renewables_power_plants/'\n",
    "    version = '2016-08-25'\n",
    "    folder = '/original_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Download function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def download_and_cache(url, session=None):\n",
    "    \"\"\"This function downloads a file into a folder called \n",
    "    original_data and returns the local filepath.\"\"\"\n",
    "    path = urllib.parse.urlsplit(url).path\n",
    "    filename = posixpath.basename(path)\n",
    "    filepath = \"input/original_data/\" + filename\n",
    "\n",
    "    #if not session:\n",
    "     #   session = requests.session()\n",
    "\n",
    "    #r = session.get(url)\n",
    "\n",
    "    # check if file exists, if not download it\n",
    "    filepath = \"input/original_data/\" + filename\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"Downloading file: \", filename)\n",
    "        r = session.get(url, stream=True)\n",
    "\n",
    "        chuncksize = 1024\n",
    "        with open(filepath, 'wb') as file:\n",
    "            for chunck in r.iter_content(chuncksize):\n",
    "                file.write(chunck)\n",
    "    else:\n",
    "        print(\"Using local file from\", filepath)\n",
    "    filepath = '' + filepath\n",
    "    return filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Setup translation dictionaries\n",
    "\n",
    "Column and value names of the original data sources will be translated to English and standardized across different sources. Standardized column names, e.g. \"electrical_capacity\" are required to merge data in on data frame.<br>\n",
    "The column and the value translation lists are provided in the input folder of the datapackage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get column translation list\n",
    "columnnames = pd.read_csv('input/column_translation_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get value translation list\n",
    "valuenames = pd.read_csv('input/value_translation_list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Download and process per country\n",
    "\n",
    "For one country after the other, the original data is downloaded, read, processed, translated, eventually georeferenced and saved. If respective files are already in the local folder, these will be utilized.\n",
    "To process the provided data [pandas DataFrame](http://pandas.pydata.org/pandas-docs/stable/dsintro.html#dataframe) is applied.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Germany DE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Download and read\n",
    "The data which will be processed below is provided by the following data sources:\n",
    "\n",
    "**[Netztransparenz.de](https://www.netztransparenz.de/de/Anlagenstammdaten.htm)** - Official grid transparency platform from the German TSOs (50Hertz, Amprion, TenneT and TransnetBW).\n",
    "\n",
    "**Bundesnetzagentur (BNetzA)** - German Federal Network Agency for Electricity, Gas, Telecommunications, Posts and Railway (Data for [roof-mounted PV power plants](http://www.bundesnetzagentur.de/cln_1422/DE/Sachgebiete/ElektrizitaetundGas/Unternehmen_Institutionen/ErneuerbareEnergien/Photovoltaik/DatenMeldgn_EEG-VergSaetze/DatenMeldgn_EEG-VergSaetze_node.html) and for [all other renewable energy power plants](http://www.bundesnetzagentur.de/cln_1412/DE/Sachgebiete/ElektrizitaetundGas/Unternehmen_Institutionen/ErneuerbareEnergien/Anlagenregister/Anlagenregister_Veroeffentlichung/Anlagenregister_Veroeffentlichungen_node.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# point URLs to original data depending on the chosen download option\n",
    "if download_from == 'original_sources':\n",
    "     \n",
    "    url_netztransparenz ='https://www.netztransparenz.de/de/file/Anlagenstammdaten_2015_final.zip'  \n",
    "    url_bnetza ='http://www.bundesnetzagentur.de/SharedDocs/Downloads/DE/Sachgebiete/Energie/Unternehmen_Institutionen/ErneuerbareEnergien/Anlagenregister/VOeFF_Anlagenregister/2016_06_Veroeff_AnlReg.xls?__blob=publicationFile&v=1'\n",
    "    url_bnetza_pv = 'https://www.bundesnetzagentur.de/SharedDocs/Downloads/DE/Sachgebiete/Energie/Unternehmen_Institutionen/ErneuerbareEnergien/Photovoltaik/Datenmeldungen/Meldungen_Aug-Mai2016.xls?__blob=publicationFile&v=2'\n",
    "    \n",
    "else:\n",
    "    url_netztransparenz = (url_opsd + version + folder + '/Netztransparenz/' + 'Anlagenstammdaten_2015.zip')\n",
    "    url_bnetza = (url_opsd + version + folder + '/BNetzA/' + '2016_06_Veroeff_AnlReg.xls')\n",
    "    url_bnetza_pv = (url_opsd + version + folder + '/BNetzA/' + 'Meldungen_Aug-Mai2016.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local file from input/original_data/Anlagenstammdaten_2015_final.zip\n",
      "CPU times: user 0 ns, sys: 4 ms, total: 4 ms\n",
      "Wall time: 21.8 ms\n",
      "Using local file from input/original_data/2016_06_Veroeff_AnlReg.xls\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 209 µs\n",
      "Using local file from input/original_data/Meldungen_Aug-Mai2016.xls\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 195 µs\n"
     ]
    }
   ],
   "source": [
    "# Download all data sets before processing.\n",
    "if download_from == 'original_sources':\n",
    "    \n",
    "    netztransparenz_zip = %time zipfile.ZipFile(download_and_cache(url_netztransparenz))\n",
    "    bnetza_xls = %time download_and_cache(url_bnetza)\n",
    "    bnetza_pv_xls = %time download_and_cache(url_bnetza_pv)\n",
    "\n",
    "else:\n",
    "    netztransparenz_zip = %time zipfile.ZipFile(download_and_cache(url_netztransparenz, session))\n",
    "    bnetza_xls = %time download_and_cache(url_bnetza, session)\n",
    "    bnetza_pv_xls = %time download_and_cache(url_bnetza_pv, session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Amprion_Anlagenstammdaten_2015.csv\n",
      "Reading 50Hertz_Anlagenstammdaten_2015.csv\n",
      "Reading TenneT_Anlagenstammdaten_2015.csv\n",
      "Reading TransnetBW_Anlagenstammdaten_2015.csv\n"
     ]
    }
   ],
   "source": [
    "# Read TSO data from zip file\n",
    "print('Reading Amprion_Anlagenstammdaten_2015.csv')\n",
    "amprion_df = pd.read_csv(netztransparenz_zip.open('Amprion_Anlagenstammdaten_2015.csv'),\n",
    "                         sep=';',\n",
    "                         thousands='.',\n",
    "                         decimal=',',\n",
    "                         header=0,\n",
    "                         parse_dates=[11, 12, 13, 14],\n",
    "                         encoding='cp1252',\n",
    "                         dayfirst=True)\n",
    "\n",
    "print('Reading 50Hertz_Anlagenstammdaten_2015.csv')\n",
    "hertz_df = pd.read_csv(netztransparenz_zip.open('50Hertz_Anlagenstammdaten_2015.csv'),\n",
    "                       sep=';',\n",
    "                       thousands='.',\n",
    "                       decimal=',',\n",
    "                       header=0,\n",
    "                       parse_dates=[11, 12, 13, 14],\n",
    "                       encoding='cp1252',\n",
    "                       dayfirst=True)\n",
    "\n",
    "print('Reading TenneT_Anlagenstammdaten_2015.csv')\n",
    "tennet_df = pd.read_csv(netztransparenz_zip.open('TenneT_Anlagenstammdaten_2015.csv'),\n",
    "                        sep=';',\n",
    "                        thousands='.',\n",
    "                        decimal=',',\n",
    "                        header=0,\n",
    "                        parse_dates=[11, 12, 13, 14],\n",
    "                        encoding='cp1252',\n",
    "                        dayfirst=True)\n",
    "\n",
    "print('Reading TransnetBW_Anlagenstammdaten_2015.csv')\n",
    "transnetbw_df = pd.read_csv(netztransparenz_zip.open('TransnetBW_Anlagenstammdaten_2015.csv'),\n",
    "                            sep=';',\n",
    "                            thousands='.',\n",
    "                            decimal=',',\n",
    "                            header=0,\n",
    "                            parse_dates=[11, 12, 13, 14],\n",
    "                            encoding='cp1252',\n",
    "                            dayfirst=True,\n",
    "                            low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bnetza - 2016_06_Veroeff_AnlReg.xls\n",
      "Reading bnetza_pv - Meldungen_Aug-Mai2016.xls\n",
      "Concatenating bnetza_pv\n"
     ]
    }
   ],
   "source": [
    "# Read BNetzA register\n",
    "print('Reading bnetza - 2016_06_Veroeff_AnlReg.xls')\n",
    "bnetza_df = pd.read_excel(bnetza_xls,\n",
    "                          sheetname='Gesamtübersicht',\n",
    "                          header=0,\n",
    "                          converters={'4.9 Postleit-zahl': str})\n",
    "\n",
    "# Read BNetzA-PV register\n",
    "print('Reading bnetza_pv - Meldungen_Aug-Mai2016.xls')\n",
    "bnetza_pv = pd.ExcelFile(bnetza_pv_xls)\n",
    "\n",
    "# Combine all PV BNetzA sheets into one data frame\n",
    "print('Concatenating bnetza_pv')\n",
    "bnetza_pv_df = pd.concat(bnetza_pv.parse(sheet, skiprows=10,\n",
    "                                         converters={'Anlage \\nPLZ': str}\n",
    "                                         ) for sheet in bnetza_pv.sheet_names)\n",
    "\n",
    "# Drop not needed NULL \"Unnamed:\" column\n",
    "bnetza_pv_df = bnetza_pv_df.drop(bnetza_pv_df.columns[[7]], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Translate column names\n",
    "To standardise the data frame the original column names from the German TSOs and the BNetzA wil be translated and new english column names wil be assigned to the data frame. The unique column names are required to merge the data frame.<br>\n",
    "The column_translation_list is provided here as csv in the input folder. It is loaded in _2.3 Setup of translation dictionaries_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translation\n"
     ]
    }
   ],
   "source": [
    "print('Translation')\n",
    "amprion_df.rename(columns=column_dict, inplace=True)\n",
    "hertz_df.rename(columns=column_dict, inplace=True)\n",
    "tennet_df.rename(columns=column_dict, inplace=True)\n",
    "transnetbw_df.rename(columns=column_dict, inplace=True)\n",
    "bnetza_df.rename(columns=column_dict, inplace=True)\n",
    "bnetza_pv_df.rename(columns=column_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.1.3 Add data source and missing information\n",
    "All data source names and (for the BNetzA-PV data) the energy source will is added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add data source names to the data frames\n",
    "transnetbw_df['data_source'] = 'TransnetBW'\n",
    "tennet_df['data_source'] = 'TenneT'\n",
    "amprion_df['data_source'] = 'Amprion'\n",
    "hertz_df['data_source'] = '50Hertz'\n",
    "bnetza_df['data_source'] = 'BNetzA'\n",
    "bnetza_pv_df['data_source'] = 'BNetzA_PV'\n",
    "\n",
    "# Add for the BNetzA PV data the energy source\n",
    "bnetza_pv_df['energy_source'] = 'solar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.4 Merge DataFrames and choose columns\n",
    "\n",
    "The individual data frames from the TSOs (Netztransparenz.de) and BNetzA will be merged together. Only some columns will be selected for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataframes = [transnetbw_df, tennet_df, amprion_df, hertz_df, bnetza_pv_df, bnetza_df]\n",
    "DE_renewables = pd.concat(dataframes)\n",
    "DE_renewables = DE_renewables.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Only these columns will be kept for the renewable power plant list output\n",
    "column_interest = ['commissioning_date','decommissioning_date','energy_source',\n",
    "                   'electrical_capacity_kW','thermal_capacity_kW','voltage_level','tso',\n",
    "                   'dso','dso_id','eeg_id','bnetza_id','federal_state',\n",
    "                   'postcode','municipality_code','municipality','address',\n",
    "                   'address_number','utm_zone','utm_east','utm_north',\n",
    "                   'notification_reason','data_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Clean dataframe from columns other than specified above\n",
    "DE_renewables = DE_renewables.loc[:, column_interest]\n",
    "DE_renewables.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First look at DataFrame structure and format**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1745311 entries, 0 to 1745310\n",
      "Data columns (total 22 columns):\n",
      "commissioning_date        datetime64[ns]\n",
      "decommissioning_date      object\n",
      "energy_source             object\n",
      "electrical_capacity_kW    float64\n",
      "thermal_capacity_kW       float64\n",
      "voltage_level             object\n",
      "tso                       object\n",
      "dso                       object\n",
      "dso_id                    object\n",
      "eeg_id                    object\n",
      "bnetza_id                 object\n",
      "federal_state             object\n",
      "postcode                  object\n",
      "municipality_code         object\n",
      "municipality              object\n",
      "address                   object\n",
      "address_number            object\n",
      "utm_zone                  float64\n",
      "utm_east                  float64\n",
      "utm_north                 float64\n",
      "notification_reason       object\n",
      "data_source               object\n",
      "dtypes: datetime64[ns](1), float64(5), object(16)\n",
      "memory usage: 292.9+ MB\n"
     ]
    }
   ],
   "source": [
    "DE_renewables.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.5 Translate values and harmonize energy source\n",
    "Different German terms for energy source, energy source subtypes and voltage levels are translated and harmonized across the individual data sources. The value_translation_list is provided here as csv in the input folder. It is loaded in _2.3 Setup of translation dictionaries_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Biomasse': 'Biomass and biogas',\n",
       " 'Deponiegas': 'Sewage and landfill gas',\n",
       " 'Freifläche PV': 'Photovoltaics ground',\n",
       " 'Geothermie': 'Geothermal',\n",
       " 'Grubengas': 'Other fossil fuels',\n",
       " 'HS': '03 (HS)',\n",
       " 'HS/MS': '04 (HS/MS)',\n",
       " 'HöS': '01 (HöS)',\n",
       " 'HöS/HS': '02 (HöS/HS)',\n",
       " 'Klärgas': 'Sewage and landfill gas',\n",
       " 'MS': '05 (MS)',\n",
       " 'MS/NS': '06 (MS/NS)',\n",
       " 'NS': '07 (NS)',\n",
       " 'Solar': 'Photovoltaics',\n",
       " 'Wasserkraft': 'Run-of-river',\n",
       " 'Wind Land': 'Onshore',\n",
       " 'Wind See': 'Offshore',\n",
       " 'Windenergie': 'Onshore',\n",
       " 'Windenergie Offshore': 'Offshore',\n",
       " 'Windenergie an Land': 'Onshore'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose the translation terms for Germany, create dictionary and show dictionary\n",
    "idx_DE = valuenames[valuenames['country'] == 'DE'].index\n",
    "value_dict_DE = valuenames.loc[idx_DE].set_index('original_name')['opsd_name'].to_dict()\n",
    "value_dict_DE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replacing..\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-16f0e52c1c64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'replacing..'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Running time: some minutes. %time prints the time your computer required for this step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time DE_renewables.replace(value_dict_DE, inplace=True)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2156\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2157\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2158\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2160\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2077\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2078\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2079\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2080\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-59>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'eval'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1177\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method, axis)\u001b[0m\n\u001b[1;32m   3360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m             return self.replace(to_replace, value, inplace=inplace,\n\u001b[0;32m-> 3362\u001b[0;31m                                 limit=limit, regex=regex)\n\u001b[0m\u001b[1;32m   3363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, to_replace, value, inplace, limit, regex, method, axis)\u001b[0m\n\u001b[1;32m   3402\u001b[0m                                                        \u001b[0mdest_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3403\u001b[0m                                                        \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3404\u001b[0;31m                                                        regex=regex)\n\u001b[0m\u001b[1;32m   3405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3406\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# [NA, ''] -> 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mreplace_list\u001b[0;34m(self, src_list, dest_list, inplace, regex, mgr)\u001b[0m\n\u001b[1;32m   2952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2953\u001b[0m         \u001b[0;31m# figure out our mask a-priori to avoid repeated replacements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2954\u001b[0;31m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2955\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2956\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcomp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mas_matrix\u001b[0;34m(self, items)\u001b[0m\n\u001b[1;32m   3148\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3149\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3150\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_interleave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/frauke/.local/lib/python3.5/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m_interleave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3157\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_interleaved_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3159\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3160\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3161\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('replacing..')\n",
    "# Running time: some minutes. %time prints the time your computer required for this step\n",
    "%time DE_renewables.replace(value_dict_DE, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Separate and assign energy source and subtypes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dictionnary in order to assign energy_source to its subtype\n",
    "energy_source_dict_DE = valuenames.loc[idx_DE].set_index('opsd_name')['energy_source'].to_dict()\n",
    "\n",
    "# Column energy_source first partly contains subtype information, thus subtype information\n",
    "# are copied to new column for energy_source_subtype\n",
    "DE_renewables['energy_source_subtype'] = DE_renewables['energy_source']\n",
    "\n",
    "# and energy source subtype values in the energy_source column are replaced\n",
    "DE_renewables['energy_source'].replace(energy_source_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "energy_source_dict_DE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Summary of DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Electrical capacity per energy_source (in MW)\n",
    "DE_renewables.groupby(['energy_source'])['electrical_capacity_kW'].sum() / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Electrical capacity per energy_source_subtype (in MW)\n",
    "DE_renewables.groupby(['energy_source_subtype'])['electrical_capacity_kW'].sum() / 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.6 Georeferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get coordinates by postcode\n",
    "*(for data with no existing geocoordinates)*\n",
    "\n",
    "The available post code in the original data provides a first approximation for the geocoordinates of the RE power plants.<br>\n",
    "The BNetzA data provides the full zip code whereas due to data privacy the TSOs only report the first three digits of the power plant's post code (e.g. 024xx) and no address. Subsequently a centroid of the post code region polygon is used to find the coordinates.\n",
    "\n",
    "With data from\n",
    "*  http://www.suche-postleitzahl.org/downloads?download=plz-gebiete.shp.zip\n",
    "*  http://www.suche-postleitzahl.org/downloads?download_file=plz-3stellig.shp.zip\n",
    "*  http://www.suche-postleitzahl.org/downloads\n",
    "\n",
    "a CSV-file for all existing German post codes with matching geocoordinates has been compiled. The latitude and longitude coordinates were generated by running a PostgreSQL + PostGIS database. Additionally the respective TSO has been added to each post code. *(A Link to the SQL script will follow here later)*\n",
    "\n",
    "*(License: http://www.suche-postleitzahl.org/downloads, Open Database Licence for free use. Source of data: © OpenStreetMap contributors)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read generated postcode/location file\n",
    "postcode = pd.read_csv('input/de_tso_postcode_gps.csv',\n",
    "                       sep=';',\n",
    "                       header=0)\n",
    "\n",
    "# Drop possible duplicates in postcodes\n",
    "postcode.drop_duplicates('postcode', keep='last',inplace=True)\n",
    "\n",
    "# Show first entries\n",
    "postcode.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "** Merge geometry information by using the postcode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take postcode and longitude/latitude informations\n",
    "postcode = postcode[[0,3,4]]\n",
    "\n",
    "DE_renewables = DE_renewables.merge(postcode, on=['postcode'],  how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform geoinformation\n",
    "*(for data with already existing geoinformation)*\n",
    "\n",
    "In this section the existing geoinformation (in UTM-format) will be transformed into latidude and longitude coordiates as a uniform standard for geoinformation. \n",
    "\n",
    "The BNetzA data set offers UTM Geoinformation with the columns *utm_zone (UTM-Zonenwert)*, *utm_east* and *utm_north*. Most of utm_east-values include the utm_zone-value **32** at the beginning of the number. In order to properly standardize and transform this geoinformation into latitude and longitude it is necessary to remove this utm_zone value. For all UTM entries the utm_zone 32 is used by the BNetzA.\n",
    "\n",
    "\n",
    "|utm_zone|\t utm_east|\t utm_north| comment|\n",
    "|---|---|---| ----|\n",
    "|32|\t413151.72|\t6027467.73| proper coordinates|\n",
    "|32|\t**32**912159.6008|\t5692423.9664| caused error by 32|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many different utm_zone values are in the data set?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DE_renewables.groupby(['utm_zone'])['utm_zone'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove the utm_zone \"32\" from the utm_east value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find entries with 32 value at the beginning\n",
    "ix_32 = (DE_renewables['utm_east'].astype(str).str[:2] == '32')\n",
    "ix_notnull = DE_renewables['utm_east'].notnull()\n",
    "\n",
    "# Remove 32 from utm_east entries\n",
    "DE_renewables.loc[ix_32,'utm_east'] = DE_renewables.loc[ix_32,'utm_east'].astype(str).str[2:].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conversion UTM to lat/lon**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert from UTM values to latitude and longitude coordinates\n",
    "try:\n",
    "    DE_renewables['lonlat'] = DE_renewables.loc[ix_notnull, ['utm_east', 'utm_north', 'utm_zone']].apply(\n",
    "        lambda x: utm.to_latlon(x[0], x[1], x[2], 'U'),\n",
    "        axis=1) \\\n",
    "        .astype(str)\n",
    "    \n",
    "except:\n",
    "    DE_renewables['lonlat'] = np.NaN\n",
    "    \n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "for row in DE_renewables['lonlat']:\n",
    "    try:\n",
    "        # Split tuple format into the column lat and lon  \n",
    "        row = row.lstrip('(').rstrip(')')\n",
    "        lat.append(row.split(',')[0])\n",
    "        lon.append(row.split(',')[1])\n",
    "    except:\n",
    "        # set NaN \n",
    "        lat.append(np.NaN)\n",
    "        lon.append(np.NaN)\n",
    "          \n",
    "\n",
    "DE_renewables['latitude'] = lat\n",
    "DE_renewables['longitude'] = lon    \n",
    "\n",
    "# Add new values to data frame lon and lat\n",
    "DE_renewables['lon'] = DE_renewables[['longitude', 'lon']].apply(\n",
    "    lambda x: x[1] if pd.isnull(x[0]) else x[0],\n",
    "    axis=1)\n",
    "\n",
    "DE_renewables['lat'] = DE_renewables[['latitude', 'lat']].apply(\n",
    "    lambda x: x[1] if pd.isnull(x[0]) else x[0],\n",
    "    axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Check: missing coordinates by data source and type**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Missing Coordinates ', DE_renewables.lat.isnull().sum())\n",
    "\n",
    "DE_renewables[DE_renewables.lat.isnull()].groupby(['energy_source',\n",
    "                                             'data_source']\n",
    "                                            )['data_source'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove temporary columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# drop lonlat column that contains both, latitute and longitude\n",
    "DE_renewables.drop(['lonlat','lon','lat'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.7 Save\n",
    " \n",
    "The merged, translated, cleaned, data frame will be saved temporily as a pickle file, which stores a python object fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DE_renewables.to_pickle('DE_renewables.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Denmark DK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 Download and read\n",
    "The data which will be processed below is provided by the following data sources:\n",
    "\n",
    "** [Energistyrelsen (ens) / Danish Energy Agency](http://www.ens.dk/info/tal-kort/statistik-noegletal/oversigt-energisektoren/stamdataregister-vindmoller)** - The wind turbines register is released by the Danish Energy Agency. \n",
    "\n",
    "** [Energinet.dk](http://www.energinet.dk/DA/El/Engrosmarked/Udtraek-af-markedsdata/Sider/Statistik.aspx)** - The data of solar power plants are released by the leading transmission network operator Denmark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# point URLs to original data depending on the chosen download option\n",
    "if download_from == 'original_sources':\n",
    "    \n",
    "    url_DK_ens = 'http://www.ens.dk/sites/ens.dk/files/info/tal-kort/statistik-noegletal/oversigt-energisektoren/stamdataregister-vindmoeller/anlaegprodtilnettet.xls'\n",
    "    url_DK_energinet = 'http://www.energinet.dk/SiteCollectionDocuments/Danske%20dokumenter/El/SolcelleGraf.xlsx'\n",
    "    url_DK_geo = 'http://download.geonames.org/export/zip/DK.zip'\n",
    "\n",
    "else:\n",
    "    url_DK_ens = (url_opsd + version + folder + '/DK/anlaegprodtilnettet.xls')\n",
    "    url_DK_energinet = (url_opsd + version + folder + '/DK/SolcelleGraf.xlsx')\n",
    "    url_DK_geo = (url_opsd + version + folder + 'DK/DK.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get wind turbines data \n",
    "DK_wind_df = pd.read_excel(download_and_cache(url_DK_ens),\n",
    "                           sheetname='IkkeAfmeldte-Existing turbines',\n",
    "                           thousands='.', \n",
    "                           header=17,\n",
    "                           skipfooter=3,\n",
    "                           parse_cols=16\n",
    "                          )\n",
    "                         \n",
    "# Get photovoltaic data\n",
    "DK_solar_df = pd.read_excel(download_and_cache(url_DK_energinet),\n",
    "                            sheetname='Data'\n",
    "                           )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2 Translate column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the translation terms for Denmark, create dictionary and show dictionary\n",
    "idx_DK = columnnames[columnnames['country'] == 'DK'].index\n",
    "column_dict_DK = columnnames.loc[idx_DK].set_index('original_name')['opsd_name'].to_dict()\n",
    "column_dict_DK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate columns by list \n",
    "DK_wind_df.rename(columns = column_dict_DK, inplace=True)\n",
    "DK_solar_df.rename(columns = column_dict_DK, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DK_wind_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DK_solar_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.3 Add data source and missing information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add names of the data sources to the data frames\n",
    "DK_wind_df['data_source'] = 'Energistyrelsen'\n",
    "DK_solar_df['data_source'] = 'Energinet.dk'\n",
    "\n",
    "# Add energy_source for each of the two data frames\n",
    "DK_wind_df['energy_source'] = 'wind'\n",
    "DK_solar_df['energy_source'] = 'solar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.4 Translate values and harmonize energy source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_DK = valuenames[valuenames['country'] == 'DK'].index\n",
    "value_dict_DK = valuenames.loc[idx_DK].set_index('original_name')['opsd_name'].to_dict()\n",
    "value_dict_DK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DK_wind_df.replace(value_dict_DK, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.5 Georeferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**UTM32 to lat/lon** *(Data from Energistyrelsen)*\n",
    "\n",
    "The Energistyrelsen data set offers UTM Geoinformation with the columns utm_east and utm_north belonging to the UTM zone 32. In this section the existing geoinformation (in UTM-format) will be transformed into latidude and longitude coordiates as a uniform standard for geoinformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Index for all values with utm information\n",
    "idx_notnull= DK_wind_df['utm_east'].notnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Convert from UTM values to latitude and longitude coordinates\n",
    "DK_wind_df['lonlat'] = DK_wind_df.loc[idx_notnull,['utm_east','utm_north']\n",
    "                                           ].apply(lambda x: utm.to_latlon(x[0],\n",
    "                                           x[1],32,'U'), axis=1).astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split latitude and longitude in two columns\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "for row in DK_wind_df['lonlat']:\n",
    "    try:\n",
    "        # Split tuple format\n",
    "        # into the column lat and lon  \n",
    "        row = row.lstrip('(').rstrip(')')\n",
    "        lat.append(row.split(',')[0])\n",
    "        lon.append(row.split(',')[1])\n",
    "    except:\n",
    "        # set NAN \n",
    "        lat.append(np.NaN)\n",
    "        lon.append(np.NaN)\n",
    "        \n",
    "DK_wind_df['latitude'] = lat\n",
    "DK_wind_df['longitude'] = lon\n",
    "\n",
    "# drop lonlat column that contains both, latitute and longitude\n",
    "DK_wind_df.drop('lonlat', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Postcode to lat/lon (WGS84)**\n",
    "*(for data from Energinet.dk)*\n",
    "\n",
    "The available post code in the original data provides an approximation for the geocoordinates of the solar power plants.<br>\n",
    "The postcode will be assigned to latitude and longitude coordinates with the help of the postcode table.\n",
    "\n",
    "** [geonames.org](http://download.geonames.org/export/zip/?C=N;O=D)** The postcode  data from Denmark is provided by Geonames and licensed under a [Creative Commons Attribution 3.0 license](http://creativecommons.org/licenses/by/3.0/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get geo-information\n",
    "zip_DK_geo = zipfile.ZipFile(download_and_cache(url_DK_geo))\n",
    "\n",
    "# Read generated postcode/location file\n",
    "DK_geo = pd.read_csv(zip_DK_geo.open('DK.txt'),sep='\\t',header=-1)\n",
    "\n",
    "# add column names as defined in associated readme file\n",
    "DK_geo.columns =  ['country_code','postcode','place_name','admin_name1',\n",
    "                   'admin_code1','admin_name2','admin_code2','admin_name3',\n",
    "                   'admin_code3','latitude','longitude','accuracy']\n",
    "\n",
    "# Drop rows of possible duplicate postal_code\n",
    "DK_geo.drop_duplicates('postcode', keep='last',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add longitude/latitude infomation assigned by postcode (for Energinet.dk data)\n",
    "DK_solar_df = DK_solar_df.merge(DK_geo[['postcode','longitude','latitude']], \n",
    "                                on=['postcode'],\n",
    "                                how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Missing Coordinates DK_wind ',DK_wind_df.latitude.isnull().sum())\n",
    "print('Missing Coordinates DK_solar ',DK_solar_df.latitude.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.6 Merge DataFrames and choose columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataframes = [DK_wind_df, DK_solar_df]\n",
    "DK_renewables = pd.concat(dataframes)\n",
    "DK_renewables = DK_renewables.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only these columns will be kept for the renewable power plant list output\n",
    "column_interest = ['commissioning_date', 'energy_source','energy_source_subtype',\n",
    "                   'electrical_capacity_kW', 'tso', 'dso','gsrn_id', 'postcode',\n",
    "                   'municipality_code','municipality','address', 'address_number',\n",
    "                   'utm_east', 'utm_north', 'longitude','latitude','hub_height',\n",
    "                   'rotor_diameter', 'manufacturer', 'model', 'data_source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean dataframe from columns other than specified above\n",
    "DK_renewables = DK_renewables.loc[:, column_interest]\n",
    "DK_renewables.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DK_renewables.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DK_renewables.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.7 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DK_renewables.to_pickle('DK_renewables.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 France FR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Download and read\n",
    "The data which will be processed below is provided by the following data source:\n",
    "\n",
    "** [Ministery of the Environment, Energy and the Sea](http://www.statistiques.developpement-durable.gouv.fr/energie-climat/r/energies-renouvelables.html?tx_ttnews%5Btt_news%5D=24638&cHash=d237bf9985fdca39d7d8c5dc84fb95f9)** - Number of installations and installed capacity of the different renewable source for every municipality in France. Service of observation and statistics, survey, date of last update: 15/12/2015. Data until 31/12/2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# point URLs to original data depending on the chosen download option\n",
    "if download_from == 'original_sources':\n",
    "    \n",
    "    url_FR_gouv = \"http://www.statistiques.developpement-durable.gouv.fr/fileadmin/documents/Themes/Energies_et_climat/Les_differentes_energies/Energies_renouvelables/donnees_locales/2014/electricite-renouvelable-par-commune-2014.xls\"\n",
    "    url_FR_geo = 'http://public.opendatasoft.com/explore/dataset/code-postal-code-insee-2015/download/?format=csv&timezone=Europe/Berlin&use_labels_for_header=true'\n",
    "\n",
    "else:\n",
    "    url_FR_gouv = (url_opsd + version + folder + '/FR/electricite-renouvelable-par-commune-2014.xls')\n",
    "    url_FR_geo = (url_opsd + version + folder + 'FR/code-postal-code-insee-2015.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get data of renewables per municipality\n",
    "FR_re_df = pd.read_excel(download_and_cache(url_FR_gouv),\n",
    "                         sheetname='Commune', \n",
    "                         encoding = 'UTF8',  \n",
    "                         thousands='.',\n",
    "                         decimals=',',\n",
    "                         header=[2, 3],\n",
    "                         skipfooter=9,  # contains summarized values\n",
    "                         index_col=[0, 1], # required for MultiIndex\n",
    "                         converters={'Code officiel géographique':str})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Rearrange columns and translate column names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The French data source contains number of installations and sum of installed capacity per energy source per municipality. The structure is adapted to the power plant list of other countries. The list is limited to the plants which are covered by article 10 of february 2000 by an agreement to a purchase commitment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Rearrange data \n",
    "FR_re_df.index.rename(['insee_com', 'municipality'], inplace=True)\n",
    "FR_re_df.columns.rename(['energy_source', None], inplace=True)\n",
    "FR_re_df = (FR_re_df\n",
    "            .stack(level='energy_source', dropna=False)\n",
    "            .reset_index(drop = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Choose the translation terms for France, create dictionary and show dictionary\n",
    "idx_FR = columnnames[columnnames['country'] == 'FR'].index\n",
    "column_dict_FR = columnnames.loc[idx_FR].set_index('original_name')['opsd_name'].to_dict()\n",
    "column_dict_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate columnnames\n",
    "FR_re_df.rename(columns = column_dict_FR, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Drop all rows that just contain NA\n",
    "FR_re_df = FR_re_df.dropna()\n",
    "FR_re_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Add data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FR_re_df['data_source'] = 'gouv.fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Translate values and harmonize energy source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Kept secret if number of installations < 3**\n",
    "\n",
    "If the number of installations is less than 3, it is marked with an _s_ instead of the number 1 or 2 due to statistical confidentiality ([further explanation by the data provider](http://www.statistiques.developpement-durable.gouv.fr/fileadmin/documents/Themes/Energies_et_climat/Les_differentes_energies/Energies_renouvelables/donnees_locales/2014/methodo-donnees-locales-electricte-renouvelable-12-2015-b.pdf)). Here, the _s_ is changed to _< 3_. This is done in the same step as the other value translations of the energy sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_FR = valuenames[valuenames['country'] == 'FR'].index\n",
    "value_dict_FR = valuenames.loc[idx_FR].set_index('original_name')['opsd_name'].to_dict()\n",
    "value_dict_FR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FR_re_df.replace(value_dict_FR, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FR_re_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 Transform MW to kW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MW to kW\n",
    "FR_re_df['electrical_capacity_MW'] *= 1000\n",
    "\n",
    "# adapt column name\n",
    "FR_re_df.rename(columns={'electrical_capacity_MW': 'electrical_capacity_kW'},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.6 Georeferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Municipality (INSEE) code to lon/lat\n",
    "The available INSEE code in the original data provides a first approximation for the geocoordinates of the renewable power plants. The following data source is utilized for assigning INSEE code to coordinates of the municipalities:\n",
    "\n",
    "** [OpenDataSoft](http://public.opendatasoft.com/explore/dataset/code-postal-code-insee-2015/information/)** publishes a list of French INSEE codes and corresponding coordinates is published under the [Licence Ouverte (Etalab)](https://www.etalab.gouv.fr/licence-ouverte-open-licence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Downlad French geo-information. As download_and_cache_function is not working\n",
    "# properly yet, thus other way of downloading\n",
    "filename = 'code_postal-insee-2015.csv'\n",
    "filepath = \"input/original_data/\" + filename\n",
    "if not os.path.exists(filepath):\n",
    "        print(\"Downloading file: \", filename)\n",
    "        FR_geo_csv = urllib.request.urlretrieve(url_FR_geo, filepath)\n",
    "else:\n",
    "        print(\"Using local file from\", filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read INSEE Code Data\n",
    "FR_geo = pd.read_csv('input/original_data/code_postal-insee-2015.csv',\n",
    "                     sep=';',\n",
    "                     header=0,\n",
    "                     converters={'Code Postal':str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create columns for latitude/longitude\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "# split in latitude/longitude\n",
    "for row in FR_geo['geo_point_2d']:\n",
    "    try:\n",
    "        # Split tuple format\n",
    "        # into the column lat and lon  \n",
    "        row = row.lstrip('(').rstrip(')')\n",
    "        lat.append(row.split(',')[0])\n",
    "        lon.append(row.split(',')[1])\n",
    "    except:\n",
    "        # set NAN \n",
    "        lat.append(np.NaN)\n",
    "        lon.append(np.NaN)\n",
    "        \n",
    "# add these columns to the INSEE data, frame\n",
    "FR_geo['latitude'] = lat\n",
    "FR_geo['longitude'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FR_re_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Column names of merge key have to be named identically\n",
    "FR_re_df.rename(columns={'municipality_code': 'insee_com'}, inplace=True)\n",
    "\n",
    "# Merge longitude and latitude columns by the Code INSEE\n",
    "FR_re_df = FR_re_df.merge(FR_geo[['insee_com','latitude','longitude']],\n",
    "                          on=['insee_com'],\n",
    "                          how='left')\n",
    "\n",
    "# Translate Code INSEE column back to municipality_code\n",
    "FR_re_df.rename(columns={'insee_com': 'municipality_code'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FR_re_df.head(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.7 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FR_re_df.to_pickle('FR_renewables.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Poland PL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1 Download and read\n",
    "The data which will be processed below is provided by the following data source:\n",
    "\n",
    "** [Urzad Regulacji Energetyki (URE) / Energy Regulatory Office](http://www.ure.gov.pl/uremapoze/mapa.html)** - Number of installations and installed capacity per energy source of renewable energy. Summed per powiat (districts) ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Polish data has to be downloaded manually \n",
    "if you have not chosen download_from = opsd_server.\n",
    "- Go to http://www.ure.gov.pl/uremapoze/mapa.html\n",
    "- Click on the British flag in the lower right corner for Englisch version\n",
    "- Set detail to highest (to the right) in the upper right corner\n",
    "- Click on the printer symbol in the lower left corner\n",
    "- 'Generate', then the rtf-file simple.rtf will be downloaded\n",
    "- Put it in the folder input/original_data on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if download_from == 'opsd_server':\n",
    "    url_PL_ure = (url_opsd + version + folder + '/PL/simple.rtf')\n",
    "    download_and_cache(url_PL_ure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read rtf-file to string with the correct encoding\n",
    "with open('input/original_data/simple.rtf', 'r') as rtf:\n",
    "    file_content = rtf.read()\n",
    "\n",
    "file_content = file_content.encode('utf-8').decode('iso-8859-2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Rearrange data from rft-file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rtf file has one table for each district in the rtf-file which needs to be separated from each and other and restructured to get all plants in one dataframe with the information: district, energy_source, number_of_installations, installed_capacity. Thus in the following, the separating items are defined, the district tables split in parts, all put in one list and afterwards transferred to a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a new line is separating all parts\n",
    "sep_split_into_parts = r'{\\fs12 \\f1 \\line }'\n",
    "# separates the table rows of each table\n",
    "sep_data_parts = r'\\trql'\n",
    "# needs more refactoring to extract the district name\n",
    "reg_exp_district = r'(?<=Powiat:).*(?=})'\n",
    "\n",
    "reg_exp_installation_type = (\n",
    "    r'(?<=\\\\fs12 \\\\f1 \\\\pard \\\\intbl \\\\ql \\\\cbpat[2|3|4] \\{\\\\fs12 \\\\f1  ).*(?=\\})')\n",
    "reg_exp_installation_value = (\n",
    "    r'(?<=\\\\fs12 \\\\f1 \\\\pard \\\\intbl \\\\qr \\\\cbpat3 \\{\\\\fs12 \\\\f1 ).*(?=})')\n",
    "\n",
    "# split file into parts\n",
    "parts = file_content.split(sep_split_into_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list containing the data\n",
    "data_set = []\n",
    "for part in parts:\n",
    "    # match district\n",
    "    district = re.findall(reg_exp_district, part)\n",
    "    if len(district) == 0:\n",
    "        pass\n",
    "    else:\n",
    "        district = district[0]\n",
    "        # log.info('Processing: ' + district)\n",
    "        # separate each part\n",
    "        data_parts = part.split(sep_data_parts)\n",
    "        # data structure: data_row = {'district': '', 'install_type': '', 'quantity': '', 'power': ''}\n",
    "        for data_rows in data_parts:\n",
    "            wrapper_list = []\n",
    "            # match each installation type\n",
    "            installation_type = re.findall(reg_exp_installation_type, data_rows)\n",
    "            for inst_type in installation_type:\n",
    "                wrapper_list.append({'district': district, 'energy_source_subtype': inst_type})\n",
    "                #wrapper_list.append({'district': district, 'install_type': inst_type})\n",
    "            # match data - contains twice as many entries as installation type (quantity, power vs. install type)\n",
    "            data_values = re.findall(reg_exp_installation_value, data_rows)\n",
    "            if len(data_values) == 0:\n",
    "                #log.debug('data values empty')\n",
    "                pass\n",
    "            else:\n",
    "                # connect data\n",
    "                for i, _ in enumerate(wrapper_list):\n",
    "                    wrapper_list[i]['number_of_installations'] = data_values[(i * 2)]\n",
    "                    wrapper_list[i]['electrical_capacity_MW'] = data_values[(i * 2) + 1]\n",
    "\n",
    "                # prepare to write to file\n",
    "                for data in wrapper_list:\n",
    "                    data_set.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mapping of malformed unicode which appear in the Polish district names\n",
    "polish_truncated_unicode_map = {\n",
    "    r'\\uc0\\u322': 'ł',\n",
    "    r'\\uc0\\u380': 'ż',\n",
    "    r'\\uc0\\u243': 'ó',\n",
    "    r'\\uc0\\u347': 'ś',\n",
    "    r'\\uc0\\u324': 'ń',\n",
    "    r'\\uc0\\u261': 'ą',\n",
    "    r'\\uc0\\u281': 'ę',\n",
    "    r'\\uc0\\u263': 'ć',\n",
    "    r'\\uc0\\u321': 'Ł',\n",
    "    r'\\uc0\\u378': 'ź',\n",
    "    r'\\uc0\\u346': 'Ś',\n",
    "    r'\\uc0\\u379': 'Ż'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# changing malformed unicode\n",
    "for entry in data_set:\n",
    "    while r'\\u' in entry['district']:\n",
    "        index = entry['district'].index(r'\\u')\n",
    "        offset = index + 9\n",
    "        to_be_replaced = entry['district'][index:offset]\n",
    "        if to_be_replaced in polish_truncated_unicode_map.keys():\n",
    "            # offset + 1 because there is a trailing whitespace\n",
    "            entry['district'] = entry['district'].replace(entry['district'][index:offset + 1],\n",
    "                                                  polish_truncated_unicode_map[to_be_replaced])\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create pandas dataframe with similar structure as the other countries\n",
    "PL_re_df = pd.DataFrame(data_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.3 Add data source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PL_re_df['data_source'] = 'Urzad Regulacji Energetyki'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.4 Translate values and harmonize energy source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx_PL = valuenames[valuenames['country'] == 'PL'].index\n",
    "value_dict_PL = valuenames.loc[idx_PL].set_index('original_name')['opsd_name'].to_dict()\n",
    "value_dict_PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "PL_re_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace install_type descriptions with energy_source subtype\n",
    "PL_re_df.energy_source_subtype.replace(value_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign energy_source_subtype to energy_source**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dictionnary in order to assign energy_source to its subtype\n",
    "energy_source_dict_PL = valuenames.loc[idx_PL].set_index('opsd_name')['energy_source'].to_dict()\n",
    "\n",
    "# Create new column for energy_source\n",
    "PL_re_df['energy_source'] = PL_re_df.energy_source_subtype\n",
    "\n",
    "# Fill this with the energy source instead of subtype information\n",
    "PL_re_df.energy_source.replace(energy_source_dict_PL, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "energy_source_dict_PL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Adjust datatype of numeric columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change type to numeric\n",
    "PL_re_df['electrical_capacity_MW'] = pd.to_numeric(PL_re_df['electrical_capacity_MW'])\n",
    "# Additionally commas are deleted\n",
    "PL_re_df['number_of_installations'] = pd.to_numeric(\n",
    "    PL_re_df['number_of_installations'].str.replace(',',''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.5 Transform MW to kW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MW to kW\n",
    "PL_re_df['electrical_capacity_MW'] *= 1000\n",
    "\n",
    "# adapt column name\n",
    "PL_re_df.rename(columns={'electrical_capacity_MW': 'electrical_capacity_kW'},\n",
    "                inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.6 Georeferencing (missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ToDo: GeoReferencing\n",
    "# to get GEOINFO\n",
    "# NTS 4 - powiats and cities with powiat status (314 + 66 units)\n",
    "# http://stat.gov.pl/en/regional-statistics/nomenclature-nts-161/\n",
    "# http://forum.geonames.org/gforum/posts/list/795.page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.7 Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PL_re_df.to_pickle('PL_renewables.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and validation of the renewable power plants list as well as the creation of CSV/XLSX/SQLite files can be found in Part 2 of this script. It also generates a daily timeseries of cumulated installed capacities by energy source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
